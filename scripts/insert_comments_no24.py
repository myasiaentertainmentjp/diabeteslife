#!/usr/bin/env python3
"""Insert 55 comments for thread No.24: é€šé™¢é »åº¦ã©ã®ãã‚‰ã„ï¼Ÿ
reply_to kept as original CSV. user_id logic:
1. Duration-keyword comments get a user whose illness_duration matches.
2. When B asks A a question (ï¼Ÿ), C's answer gets A's user_id.
"""

import uuid
import json
import urllib.request
from datetime import datetime, timedelta, timezone

SUPABASE_URL = "https://josanlblwfjdaaezqbnw.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Impvc2FubGJsd2ZqZGFhZXpxYm53Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2Nzg0MjYwNiwiZXhwIjoyMDgzNDE4NjA2fQ.JlTXBmY5HJAqfRD_AazsiBORpgLZfB74fPkNyyfVSQY"

THREAD_ID = "2ffbf01d-9fff-4c12-98fe-dda589234191"
THREAD_OWNER_ID = "2033ee1c-28b2-5187-8ba1-c94f7964e33e"

USERS = [
    "b0000001-0000-0000-0000-000000000001",  # ã‚ˆã£ã—ãƒ¼    1_to_3
    "b0000001-0000-0000-0000-000000000002",  # ã¾ã‚†ã¿      less_than_1
    "b0000001-0000-0000-0000-000000000003",  # ãŸã‘ã—      less_than_1
    "b0000001-0000-0000-0000-000000000004",  # ã•ã¡ã“      3_to_5
    "b0000001-0000-0000-0000-000000000005",  # ã“ã†ãŸ      less_than_1
    "b0000001-0000-0000-0000-000000000006",  # ã‚†ã‹ã‚Š      1_to_3
    "b0000001-0000-0000-0000-000000000007",  # ã¾ã•ã²ã‚    1_to_3
    "b0000001-0000-0000-0000-000000000008",  # ã¨ã‚‚ã“      less_than_1
    "b0000001-0000-0000-0000-000000000009",  # ã—ã‚“ã˜      5_to_10
    "b0000001-0000-0000-0000-000000000010",  # ã²ã‚ã¿      3_to_5
    "b0000001-0000-0000-0000-000000000011",  # ã ã„ã™ã‘    5_to_10
    "b0000001-0000-0000-0000-000000000012",  # ã‚ã‘ã¿      1_to_3
    "b0000001-0000-0000-0000-000000000013",  # ã‘ã‚“ãŸ      less_than_1
    "b0000001-0000-0000-0000-000000000014",  # ã¿ã¡ã“      1_to_3
    "b0000001-0000-0000-0000-000000000015",  # ã‚Šã‚‡ã†ãŸ    10_plus
    "b0000001-0000-0000-0000-000000000016",  # ãªãŠã“      less_than_1
    "b0000001-0000-0000-0000-000000000017",  # ã¦ã¤ã‚„      10_plus
    "b0000001-0000-0000-0000-000000000018",  # ã‹ãšãˆ      3_to_5
    "b0000001-0000-0000-0000-000000000019",  # ã‚†ã†ã‚„      10_plus
    "b0000001-0000-0000-0000-000000000020",  # ã‚Œã„ã“      1_to_3
    "f0000001-0000-0000-0000-000000000001",  # ã¿ãƒ¼ãƒžãƒž    family
    "f0000001-0000-0000-0000-000000000002",  # ã‚±ãƒ³ãƒ‘ãƒ‘    family
    "f0000001-0000-0000-0000-000000000003",  # ã•ãã‚‰ðŸŒ¸    family
    "f0000001-0000-0000-0000-000000000004",  # ãŸã£ãã‚“çˆ¶  family
    "f0000001-0000-0000-0000-000000000005",  # ã‚†ã†ã“      family
    "f0000001-0000-0000-0000-000000000006",  # ã‘ã‚“ã˜      family
    "f0000001-0000-0000-0000-000000000008",  # ã¾ã•ãŠ      family
    "f0000001-0000-0000-0000-000000000009",  # ã²ãªã®      family
    "f0000001-0000-0000-0000-000000000010",  # ã¨ã—ã      family
    THREAD_OWNER_ID,                          # Ash        5_to_10
]

USER_DURATION = {
    "b0000001-0000-0000-0000-000000000001": "1_to_3",
    "b0000001-0000-0000-0000-000000000002": "less_than_1",
    "b0000001-0000-0000-0000-000000000003": "less_than_1",
    "b0000001-0000-0000-0000-000000000004": "3_to_5",
    "b0000001-0000-0000-0000-000000000005": "less_than_1",
    "b0000001-0000-0000-0000-000000000006": "1_to_3",
    "b0000001-0000-0000-0000-000000000007": "1_to_3",
    "b0000001-0000-0000-0000-000000000008": "less_than_1",
    "b0000001-0000-0000-0000-000000000009": "5_to_10",
    "b0000001-0000-0000-0000-000000000010": "3_to_5",
    "b0000001-0000-0000-0000-000000000011": "5_to_10",
    "b0000001-0000-0000-0000-000000000012": "1_to_3",
    "b0000001-0000-0000-0000-000000000013": "less_than_1",
    "b0000001-0000-0000-0000-000000000014": "1_to_3",
    "b0000001-0000-0000-0000-000000000015": "10_plus",
    "b0000001-0000-0000-0000-000000000016": "less_than_1",
    "b0000001-0000-0000-0000-000000000017": "10_plus",
    "b0000001-0000-0000-0000-000000000018": "3_to_5",
    "b0000001-0000-0000-0000-000000000019": "10_plus",
    "b0000001-0000-0000-0000-000000000020": "1_to_3",
    THREAD_OWNER_ID: "5_to_10",
}

USERS_BY_DURATION = {
    "less_than_1": [u for u in USERS if USER_DURATION.get(u) == "less_than_1"],
    "1_to_3":      [u for u in USERS if USER_DURATION.get(u) == "1_to_3"],
    "3_to_5":      [u for u in USERS if USER_DURATION.get(u) == "3_to_5"],
    "5_to_10":     [u for u in USERS if USER_DURATION.get(u) == "5_to_10"],
    "10_plus":     [u for u in USERS if USER_DURATION.get(u) == "10_plus"],
}

DURATION_KEYWORDS = [
    ("10_plus",     ["10å¹´ä»¥ä¸Š", "15å¹´", "20å¹´", "30å¹´", "10å¹´é¸æ‰‹"]),
    ("5_to_10",     ["5å¹´ä»¥ä¸Š", "7å¹´", "8å¹´", "9å¹´", "6å¹´", "è¨ºæ–­ã•ã‚Œã¦5å¹´", "è¨ºæ–­ã•ã‚Œã¦6å¹´", "è¨ºæ–­ã•ã‚Œã¦7å¹´", "è¨ºæ–­ã•ã‚Œã¦8å¹´"]),
    ("3_to_5",      ["4å¹´ç›®", "5å¹´ç›®", "4å¹´çµŒ", "5å¹´çµŒ", "è¨ºæ–­ã•ã‚Œã¦4å¹´"]),
    ("1_to_3",      ["2å¹´ç›®", "3å¹´ç›®", "2å¹´çµŒ", "3å¹´çµŒ", "è¨ºæ–­ã•ã‚Œã¦2å¹´", "è¨ºæ–­ã•ã‚Œã¦3å¹´", "è¨ºæ–­ã•ã‚Œã¦1å¹´"]),
    ("less_than_1", ["1å¹´æœªæº€", "åŠå¹´", "æœ€è¿‘è¨ºæ–­", "è¨ºæ–­ã•ã‚ŒãŸã°ã‹ã‚Š", "è¨ºæ–­ã•ã‚Œã¦æ•°ãƒ¶æœˆ"]),
]


def detect_duration(body):
    for category, keywords in DURATION_KEYWORDS:
        for kw in keywords:
            if kw in body:
                return category
    return None


COMMENTS = [
    (2, None, "ã¿ãªã•ã‚“é€šé™¢ã©ã®ãã‚‰ã„ã®é »åº¦ã§è¡Œã£ã¦ã¾ã™ã‹ï¼Ÿ", "2025-12-16 19:00"),
    (3, 2, "æœˆ1å›žã§ã™ã€‚è–¬ã‚‚ã‚‰ã†ã¤ã„ã§ã«", "2025-12-16 19:30"),
    (4, 2, "2ãƒ¶æœˆã«1å›žã§ã™ã€‚å®‰å®šã—ã¦ã‚‹ã‹ã‚‰", "2025-12-16 20:00"),
    (5, None, "è¨ºæ–­ã•ã‚ŒãŸã°ã‹ã‚Šã®é ƒã¯2é€±é–“ã«1å›žã ã£ãŸ", "2025-12-16 21:00"),
    (6, 5, "æœ€åˆã¯é »ç¹ã§ã™ã‚ˆã­ã€‚ç§ã‚‚æœ€åˆã¯æœˆ2å›žã§ã—ãŸ", "2025-12-17 08:00"),
    (7, None, "3ãƒ¶æœˆã«1å›žã®äººã„ã¾ã™ã‹ï¼Ÿ", "2025-12-17 12:00"),
    (8, 7, "ã¯ã„ã€HbA1cå®‰å®šã—ã¦ã‚‹ã‹ã‚‰3ãƒ¶æœˆã”ã¨ã«ãªã‚Šã¾ã—ãŸ", "2025-12-17 13:00"),
    (9, 7, "ç§ã‚‚ã§ã™ã€‚10å¹´ä»¥ä¸Šé€šã£ã¦ã‚„ã£ã¨3ãƒ¶æœˆã«ãªã£ãŸ", "2025-12-17 19:00"),
    (10, None, "é€šé™¢æ—¥ã£ã¦ä»•äº‹ä¼‘ã‚“ã§ã¾ã™ã‹ï¼Ÿ", "2025-12-17 20:00"),
    (11, 10, "åœŸæ›œæ—¥ã«ã‚„ã£ã¦ã‚‹ç—…é™¢ã«å¤‰ãˆã¾ã—ãŸ", "2025-12-17 20:30"),
    (12, 10, "æœ‰çµ¦ä½¿ã£ã¦ã¾ã™ã€‚æœˆ1ã ã‹ã‚‰ä»•æ–¹ãªã„", "2025-12-17 21:30"),
    (13, None, "é€šé™¢è²»ã£ã¦æœˆã©ã®ãã‚‰ã„ã‹ã‹ã‚Šã¾ã™ã‹ï¼Ÿ", "2025-12-18 12:00"),
    (14, 13, "è¨ºå¯Ÿã¨è–¬ã§5000å††ãã‚‰ã„ã§ã™", "2025-12-18 12:30"),
    (15, 13, "ã‚¤ãƒ³ã‚¹ãƒªãƒ³ä½¿ã£ã¦ã‚‹ã‹ã‚‰8000å††ãã‚‰ã„ã‹ã‹ã‚‹", "2025-12-18 19:00"),
    (16, 15, "ã‚¤ãƒ³ã‚¹ãƒªãƒ³ã¯é«˜ã„ã§ã™ã‚ˆã­â€¦", "2025-12-18 19:30"),
    (17, None, "å¾…ã¡æ™‚é–“ãŒé•·ãã¦è¾›ã„", "2025-12-18 20:30"),
    (18, 17, "äºˆç´„åˆ¶ã®ç—…é™¢ã«å¤‰ãˆãŸã‚‰æ¥½ã«ãªã‚Šã¾ã—ãŸ", "2025-12-19 08:00"),
    (19, 17, "æœã‚¤ãƒã§è¡Œãã‚ˆã†ã«ã—ã¦ã¾ã™", "2025-12-19 12:00"),
    (20, None, "çœ¼ç§‘ã¨æ­¯ç§‘ã‚‚å®šæœŸçš„ã«è¡Œã£ã¦ã¾ã™ã‹ï¼Ÿ", "2025-12-19 19:00"),
    (21, 20, "çœ¼ç§‘ã¯å¹´1å›žã€çœ¼åº•æ¤œæŸ»ã—ã¦ã¾ã™", "2025-12-19 19:30"),
    (22, 20, "æ­¯ç§‘ã¯3ãƒ¶æœˆã”ã¨ã€‚ç³–å°¿ç—…ã ã¨æ­¯å‘¨ç—…ãªã‚Šã‚„ã™ã„ã‹ã‚‰", "2025-12-19 20:30"),
    (23, 21, "çœ¼ç§‘å¤§äº‹ã§ã™ã‚ˆã­ã€‚ç§ã‚‚è¨ºæ–­ã•ã‚Œã¦2å¹´ç›®ã‹ã‚‰è¡Œãå§‹ã‚ãŸ", "2025-12-19 21:00"),
    (24, None, "é€šé™¢ã‚µãƒœã£ãŸã“ã¨ã‚ã‚‹äººã„ã¾ã™ã‹ï¼Ÿ", "2025-12-20 14:00"),
    (25, 24, "æ­£ç›´ã‚ã‚Šã¾ã™â€¦å¿™ã—ãã¦3ãƒ¶æœˆç©ºã„ã¡ã‚ƒã£ãŸ", "2025-12-20 15:00"),
    (26, 24, "ã‚µãƒœã‚‹ã¨ä½™è¨ˆæ‚ªåŒ–ã™ã‚‹ã‹ã‚‰é ‘å¼µã£ã¦è¡Œã£ã¦ã¾ã™", "2025-12-20 19:00"),
    (27, 25, "å…ˆç”Ÿã«æ€’ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼Ÿ", "2025-12-20 20:00"),
    (28, 27, "æ³¨æ„ã•ã‚Œã¾ã—ãŸã‘ã©ã€æ¥ã¦ãã‚Œã¦è‰¯ã‹ã£ãŸã£ã¦è¨€ã‚ã‚Œã¾ã—ãŸ", "2025-12-20 21:00"),
    (29, None, "å¹´æœ«å¹´å§‹ã¯ç—…é™¢ä¼‘ã¿ã ã‹ã‚‰æ—©ã‚ã«è¡Œã‹ãªã„ã¨", "2025-12-21 14:00"),
    (30, 29, "ç§ã¯å…ˆé€±è¡Œã£ã¦ãã¾ã—ãŸã€‚è–¬ã‚‚å¤šã‚ã«ã‚‚ã‚‰ã£ãŸ", "2025-12-21 15:00"),
    (31, 29, "å¿˜ã‚Œã¦ãŸï¼æ˜Žæ—¥è¡Œã‹ãªãã‚ƒ", "2025-12-21 19:00"),
    (32, None, "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¨ºç™‚ä½¿ã£ã¦ã‚‹äººã„ã¾ã™ã‹ï¼Ÿ", "2025-12-22 12:00"),
    (33, 32, "ã‚³ãƒ­ãƒŠç¦ã‹ã‚‰ä½¿ã£ã¦ã¾ã™ã€‚ä¾¿åˆ©ã§ã™ã‚ˆ", "2025-12-22 13:00"),
    (34, 32, "è¡€æ¶²æ¤œæŸ»ãŒã‚ã‚‹æ™‚ã¯è¡Œã‹ãªã„ã¨ã ã‘ã©ã€è–¬ã ã‘ã®æ™‚ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«ã—ã¦ã¾ã™", "2025-12-22 19:00"),
    (35, 33, "ã©ã“ã®ã‚µãƒ¼ãƒ“ã‚¹ä½¿ã£ã¦ã¾ã™ã‹ï¼Ÿ", "2025-12-22 20:00"),
    (36, 35, "ç—…é™¢ãŒç‹¬è‡ªã§ã‚„ã£ã¦ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ã‚¢ãƒ—ãƒªã§ãƒ“ãƒ‡ã‚ªé€šè©±ã™ã‚‹æ„Ÿã˜", "2025-12-22 21:00"),
    (37, None, "ä¸»æ²»åŒ»ã¨ã®ç›¸æ€§ã£ã¦å¤§äº‹ã§ã™ã‚ˆã­", "2025-12-23 14:00"),
    (38, 37, "åˆã‚ãªãã¦ç—…é™¢å¤‰ãˆãŸã“ã¨ã‚ã‚Šã¾ã™", "2025-12-23 15:00"),
    (39, 37, "è©±ã—ã‚„ã™ã„å…ˆç”Ÿã ã¨é€šé™¢ã‚‚è‹¦ã˜ã‚ƒãªã„", "2025-12-23 19:00"),
    (40, None, "æ¤œæŸ»ã®æ—¥ã£ã¦æœã”ã¯ã‚“é£Ÿã¹ã¦ã„ã„ã®ï¼Ÿ", "2025-12-24 08:00"),
    (41, 40, "ç©ºè…¹æ™‚è¡€ç³–æ¸¬ã‚‹æ™‚ã¯æŠœã„ã¦ãã ã•ã„ã£ã¦è¨€ã‚ã‚Œã¦ã¾ã™", "2025-12-24 09:00"),
    (42, 40, "ç§ã®ç—…é™¢ã¯é£Ÿå¾Œã§ã‚‚OKã£ã¦è¨€ã‚ã‚ŒãŸã€‚HbA1cãƒ¡ã‚¤ãƒ³ã ã‹ã‚‰", "2025-12-24 12:00"),
    (43, None, "å¹´æ˜Žã‘æœ€åˆã®é€šé™¢ã„ã¤ã§ã™ã‹ï¼Ÿ", "2025-12-27 19:00"),
    (44, 43, "1æœˆ6æ—¥ã§ã™ã€‚æ­£æœˆã®çµæžœãŒæ€–ã„", "2025-12-27 19:30"),
    (45, 43, "1æœˆä¸­æ—¬ã€‚ã¡ã‚‡ã£ã¨é–“ç©ºãã‹ã‚‰å¿ƒé…", "2025-12-27 20:30"),
    (46, None, "é€šé™¢æ­´é•·ã„äººã€ç—…é™¢å¤‰ãˆãŸã“ã¨ã‚ã‚Šã¾ã™ã‹ï¼Ÿ", "2025-12-28 14:00"),
    (47, 46, "å¼•ã£è¶Šã—ã§å¤‰ãˆã¾ã—ãŸã€‚ç´¹ä»‹çŠ¶æ›¸ã„ã¦ã‚‚ã‚‰ã£ãŸ", "2025-12-28 15:00"),
    (48, 46, "10å¹´ä»¥ä¸ŠåŒã˜ç—…é™¢ã§ã™ã€‚å…ˆç”Ÿã‚‚å¤‰ã‚ã‚‰ãªã„ã—å®‰å¿ƒ", "2025-12-28 19:00"),
    (49, None, "ã‚ã‘ã¾ã—ã¦ãŠã‚ã§ã¨ã†ã€‚ä»Šå¹´ã‚‚é€šé™¢é ‘å¼µã‚ã†", "2026-01-01 10:00"),
    (50, 49, "ã‚ã‘ãŠã‚ï¼å¥åº·ç¬¬ä¸€ã§", "2026-01-01 11:00"),
    (51, None, "ä»Šå¹´ã‹ã‚‰ç³–å°¿ç—…å°‚é–€åŒ»ã®ã„ã‚‹ç—…é™¢ã«å¤‰ãˆã‚ˆã†ã‹ãª", "2026-01-03 14:00"),
    (52, 51, "å°‚é–€åŒ»ã„ã‚‹ã¨å®‰å¿ƒã§ã™ã‚ˆã­ã€‚æ²»ç™‚ã®é¸æŠžè‚¢ã‚‚å¢—ãˆã‚‹ã—", "2026-01-03 15:00"),
    (53, None, "é€šé™¢ã£ã¦é¢å€’ã ã‘ã©ã€ã‚µãƒœã‚‹ã¨å¾Œã§å¤§å¤‰ã ã‹ã‚‰ç¶šã‘ã¦ã‚‹", "2026-01-05 19:00"),
    (54, 53, "ç¶™ç¶šãŒå¤§äº‹ã§ã™ã‚ˆã­", "2026-01-05 19:30"),
    (55, None, "ã“ã®ã‚¹ãƒ¬è¦‹ã¦é€šé™¢ã®å¤§åˆ‡ã•å†ç¢ºèªã—ãŸ", "2026-01-06 19:00"),
    (56, 55, "ãŠäº’ã„é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼", "2026-01-06 19:30"),
]


def jst_to_utc(jst_str):
    dt = datetime.strptime(jst_str, "%Y-%m-%d %H:%M")
    dt_utc = dt - timedelta(hours=9)
    return dt_utc.strftime("%Y-%m-%dT%H:%M:%S+00:00")


def assign_user_ids(comments):
    user_map = {}
    body_map = {}
    reply_map = {}
    for num, reply_to, body, dt in comments:
        body_map[num] = body
        reply_map[num] = reply_to

    dur_idx = {k: 0 for k in USERS_BY_DURATION}
    user_idx = 0

    for num, reply_to, body, dt in comments:
        # 1. Duration keyword match
        dur_cat = detect_duration(body)
        if dur_cat and USERS_BY_DURATION.get(dur_cat):
            group = USERS_BY_DURATION[dur_cat]
            idx = dur_idx[dur_cat] % len(group)
            candidate = group[idx]
            if reply_to and reply_to in user_map and candidate == user_map[reply_to]:
                dur_idx[dur_cat] += 1
                idx = dur_idx[dur_cat] % len(group)
                candidate = group[idx]
            user_map[num] = candidate
            dur_idx[dur_cat] += 1
            print(f"  #{num}: duration match ({dur_cat}) -> {candidate[-3:]}")
            continue

        # 2. A->B(ï¼Ÿ)->C pattern
        if reply_to and reply_to in reply_map:
            B_num = reply_to
            A_num = reply_map[B_num]
            B_body = body_map.get(B_num, "")
            if A_num and "ï¼Ÿ" in B_body and A_num in user_map:
                user_map[num] = user_map[A_num]
                print(f"  #{num}: question-answer -> same as #{A_num}")
                continue

        # 3. Normal assignment
        if reply_to and reply_to in user_map:
            parent_user = user_map[reply_to]
            candidate = USERS[user_idx % len(USERS)]
            while candidate == parent_user:
                user_idx += 1
                candidate = USERS[user_idx % len(USERS)]
            user_map[num] = candidate
            user_idx += 1
        else:
            user_map[num] = USERS[user_idx % len(USERS)]
            user_idx += 1

    return user_map


def insert_batch(records, batch_num):
    url = f"{SUPABASE_URL}/rest/v1/comments"
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "return=minimal",
    }
    data = json.dumps(records).encode("utf-8")
    req = urllib.request.Request(url, data=data, headers=headers, method="POST")
    try:
        with urllib.request.urlopen(req) as resp:
            print(f"  Batch {batch_num}: {resp.status} - {len(records)} records inserted")
            return True
    except urllib.error.HTTPError as e:
        print(f"  Batch {batch_num}: ERROR {e.code} - {e.read().decode()}")
        return False


def main():
    print(f"Processing {len(COMMENTS)} comments for thread No.24")
    print(f"Thread ID: {THREAD_ID}")
    print()

    comment_uuids = {}
    for num, _, _, _ in COMMENTS:
        comment_uuids[num] = str(uuid.uuid4())

    print("Assigning user IDs...")
    user_map = assign_user_ids(COMMENTS)
    print()

    records = []
    now_utc = datetime.now(timezone.utc)
    past_count = 0
    future_count = 0

    for num, reply_to, body, dt_jst in COMMENTS:
        utc_str = jst_to_utc(dt_jst)
        dt_obj = datetime.strptime(dt_jst, "%Y-%m-%d %H:%M").replace(tzinfo=timezone(timedelta(hours=9)))
        if dt_obj > now_utc:
            future_count += 1
        else:
            past_count += 1

        parent_id = comment_uuids[reply_to] if reply_to else None
        record = {
            "id": comment_uuids[num],
            "thread_id": THREAD_ID,
            "body": body,
            "user_id": user_map[num],
            "is_hidden": False,
            "created_at": utc_str,
            "parent_id": parent_id,
        }
        records.append(record)

    print(f"Past comments: {past_count}")
    print(f"Future comments: {future_count}")
    print(f"Total: {len(records)}")
    print()

    BATCH_SIZE = 50
    for i in range(0, len(records), BATCH_SIZE):
        batch = records[i:i+BATCH_SIZE]
        batch_num = i // BATCH_SIZE + 1
        if not insert_batch(batch, batch_num):
            print("STOPPING due to error")
            return

    print(f"\nAll {len(records)} comments inserted!")

    print(f"\nUpdating comments_count to {past_count}...")
    url = f"{SUPABASE_URL}/rest/v1/threads?id=eq.{THREAD_ID}"
    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "return=minimal",
    }
    data = json.dumps({"comments_count": past_count}).encode("utf-8")
    req = urllib.request.Request(url, data=data, headers=headers, method="PATCH")
    try:
        with urllib.request.urlopen(req) as resp:
            print(f"  Updated: {resp.status}")
    except urllib.error.HTTPError as e:
        print(f"  ERROR: {e.code} - {e.read().decode()}")


if __name__ == "__main__":
    main()
