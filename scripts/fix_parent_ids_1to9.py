#!/usr/bin/env python3
"""Fix parent_id issues in threads 1 and 7 (14 total fixes)."""

import json
import urllib.request
import urllib.parse

SUPABASE_URL = "https://josanlblwfjdaaezqbnw.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Impvc2FubGJsd2ZqZGFhZXpxYm53Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2Nzg0MjYwNiwiZXhwIjoyMDgzNDE4NjA2fQ.JlTXBmY5HJAqfRD_AazsiBORpgLZfB74fPkNyyfVSQY"

HEADERS = {
    "apikey": SUPABASE_KEY,
    "Authorization": f"Bearer {SUPABASE_KEY}",
    "Content-Type": "application/json",
}

FIXES = {
    # 1. ä»Šæ—¥ã®è¡€ç³–å€¤ã©ã†ã ã£ãŸ (12 fixes)
    "a0000001-1215-0001-0001-000000000001": [
        (40, 39, 38),    # "å¯ã‚‹å‰ã®é–“é£Ÿã‚„ã‚ãŸã®ãŒåŠ¹ã„ãŸã‹ã‚‚" â†’ #38ã¸
        (43, 42, 41),    # "0.3ä¸‹ãŒã£ã¦ã¾ã—ãŸï¼å¬‰ã—ã„ğŸ˜Š" â†’ #41ã¸
        (50, 49, 48),    # "ãƒ–ãƒ‰ã‚¦ç³–èˆã‚ãŸã‚‰è½ã¡ç€ãã¾ã—ãŸ" â†’ #48ã¸
        (53, 52, 51),    # "ã‚„ã£ã¦ã¿ã¾ã™ï¼ã‚ã‚ŠãŒã¨ã†" â†’ #51ã¸
        (73, 72, 71),    # "ã‚µãƒ©ãƒ€ãƒãƒ¼ä»˜ãã®ãŠåº—ã«ã—ã¾ã—ãŸ" â†’ #71ã¸
        (115, 114, 113), # "A1cç¶­æŒã§ãã¦ã¾ã—ãŸï¼" â†’ #113ã¸
        (160, 159, 158), # "é–“é£Ÿæ¸›ã‚‰ã—ãŸã®ãŒåŠ¹ã„ãŸã‹ã‚‚" â†’ #158ã¸
        (164, 163, 162), # "é£Ÿå¾Œ1æ™‚é–“ã§æ­©ãã¨å…¨ç„¶é•ã†ï¼" â†’ #162ã¸
        (168, 167, 165), # "A1cä¸‹ãŒã£ã¦ã¾ã—ãŸï¼å¬‰ã—ã„ğŸ˜Š" â†’ #165ã¸
        (183, 182, 181), # "85%ã¯è‹¦ã‹ã£ãŸç¬‘ 70%ãŒã¡ã‚‡ã†ã©ã„ã„" â†’ #181ã¸
        (189, 188, 187), # "é£Ÿã¹ã‚‹æ™‚é–“ã‚’å›ºå®šã—ãŸã®ãŒã‚ˆã‹ã£ãŸã‹ã‚‚" â†’ #187ã¸
        (193, 192, 191), # "ãã‚Œã„ã„ã­ï¼ã‚„ã£ã¦ã¿ã‚‹" â†’ #191ã¸
    ],
    # 7. ä½è¡€ç³–ã«ã‚ˆã‚‹æ‚©ã¿ (2 fixes)
    "a0000001-1220-0007-0001-000000000001": [
        (15, 14, 13),    # "å¯¾å‡¦ç™‚æ³•çš„ã«ã¯ç”˜ã„ã‚‚ã®ãªã‚“ã ã‘ã©..." â†’ #13ã¸
        (16, 14, 13),    # "ãƒŠãƒƒãƒ„ãŒã„ã„ã‚‰ã—ã„ã‚ˆ..." â†’ #13ã¸
    ],
}


def fetch_comments(thread_id):
    params = urllib.parse.urlencode({
        "thread_id": f"eq.{thread_id}",
        "select": "id,body,created_at,parent_id",
        "order": "created_at.asc",
        "limit": "1000",
    })
    url = f"{SUPABASE_URL}/rest/v1/comments?{params}"
    headers = {**HEADERS, "Prefer": "return=representation"}
    req = urllib.request.Request(url, headers=headers, method="GET")
    with urllib.request.urlopen(req) as resp:
        return json.loads(resp.read().decode())


def update_parent(comment_id, new_parent_id):
    url = f"{SUPABASE_URL}/rest/v1/comments?id=eq.{comment_id}"
    headers = {**HEADERS, "Prefer": "return=minimal"}
    data = json.dumps({"parent_id": new_parent_id}).encode("utf-8")
    req = urllib.request.Request(url, data=data, headers=headers, method="PATCH")
    with urllib.request.urlopen(req) as resp:
        return resp.status


def main():
    total = sum(len(f) for f in FIXES.values())
    print(f"Fixing {total} parent_id references across {len(FIXES)} threads\n")

    fixed = 0
    errors = 0

    for thread_id, fixes in FIXES.items():
        comments = fetch_comments(thread_id)
        print(f"Thread: {thread_id} ({len(comments)} comments)")

        num_to_id = {}
        for i, c in enumerate(comments):
            num = i + 2
            num_to_id[num] = c["id"]

        for comment_num, wrong_parent_num, correct_parent_num in fixes:
            comment_id = num_to_id.get(comment_num)
            correct_parent_id = num_to_id.get(correct_parent_num)

            if not comment_id or not correct_parent_id:
                print(f"  ERROR: #{comment_num} or #{correct_parent_num} not found")
                errors += 1
                continue

            actual = comments[comment_num - 2]
            try:
                update_parent(comment_id, correct_parent_id)
                body = actual["body"][:40]
                print(f"  #{comment_num} parent: #{wrong_parent_num} â†’ #{correct_parent_num} OK  \"{body}\"")
                fixed += 1
            except Exception as e:
                print(f"  #{comment_num} ERROR: {e}")
                errors += 1

        print()

    print(f"Done. Fixed: {fixed}, Errors: {errors}")


if __name__ == "__main__":
    main()
